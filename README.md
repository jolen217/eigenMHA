# Flash-LightSeq
## Plans
* Use LightSeq with Flash-Attention to train and inference Transformer models.
  * with your own AutoGrad
  * with an application in time-series-prediction
  * using both CPU and GPU
